## 周学习总结 
<!-- TOC -->

- [周学习总结](#周学习总结)
  - [`第1周学习总结`](#第1周学习总结)
    - [一、整理并总结原来读的注意力机制论文](#一整理并总结原来读的注意力机制论文)
    - [二、学习xshell和xftp](#二学习xshell和xftp)
    - [三、学习Linux相关内容](#三学习linux相关内容)
    - [四、下周计划](#四下周计划)
  - [`第2周学习总结`](#第2周学习总结)
    - [一、学习注意力机制的实现](#一学习注意力机制的实现)
    - [二、通过远端服务器运行代码](#二通过远端服务器运行代码)
    - [三、读《基于深度学习的调制识别技术研究——雷志坤》](#三读基于深度学习的调制识别技术研究雷志坤)
    - [四、下周计划](#四下周计划-1)
  - [`第3周学习总结`](#第3周学习总结)
    - [一、搭建VGG+注意力网络架构](#一搭建vgg注意力网络架构)
    - [二、可视化](#二可视化)
    - [三、阅读雷志坤论文并总结](#三阅读雷志坤论文并总结)
    - [四、下周计划](#四下周计划-2)
  - [`第5周学习总结`](#第5周学习总结)
    - [一、修改开题报告](#一修改开题报告)
    - [二、阅读论文Context Aware Query Image Representation for Particular Object Retrieval](#二阅读论文context-aware-query-image-representation-for-particular-object-retrieval)
    - [三、学习空间转移网络（STN）](#三学习空间转移网络stn)
    - [四、下周计划](#四下周计划-3)
  - [`第6周学习总结`](#第6周学习总结)
    - [一、读论文Spatial Transformer Network](#一读论文spatial-transformer-network)
    - [二、学习STN代码](#二学习stn代码)
    - [三、重新生成星座图，熟悉理想信道下不同调制类型的星座图，并观察与所用数据集生成的星座图的区别。](#三重新生成星座图熟悉理想信道下不同调制类型的星座图并观察与所用数据集生成的星座图的区别)
    - [四、下周计划](#四下周计划-4)
  - [`第7周学习总结`](#第7周学习总结)
    - [一、准备开题答辩](#一准备开题答辩)
    - [二、读论文PARTICULAR OBJECT RETRIEVAL WITH INTEGRAL MAX-POOLING OF CNN ACTIVATIONS](#二读论文particular-object-retrieval-with-integral-max-pooling-of-cnn-activations)
    - [三、下周计划](#三下周计划)
  - [`第8周学习总结`](#第8周学习总结)
    - [一、学习STN的处理过程](#一学习stn的处理过程)
    - [二、使用 screen 管理远程会话](#二使用-screen-管理远程会话)
    - [三、阅读论文A practical theory for designing very deep convolutional neural networks](#三阅读论文a-practical-theory-for-designing-very-deep-convolutional-neural-networks)
    - [四、下周计划](#四下周计划-5)
  - [`第9周学习总结`](#第9周学习总结)
    - [一、阅读论文Deep Image Retrieval:Learning gloabal representations for image retrieval](#一阅读论文deep-image-retrievallearning-gloabal-representations-for-image-retrieval)
    - [二、空间池化金字塔（SPP）](#二空间池化金字塔spp)
    - [三、amber代码实现](#三amber代码实现)
    - [四、下周计划](#四下周计划-6)
  - [`第10周学习总结`](#第10周学习总结)
    - [一、阅读论文Deep Architectures for Modulation Recognition](#一阅读论文deep-architectures-for-modulation-recognition)
    - [二、阅读论文Radio Transformer Networks: Attention Models for Learning to Synchronize in Wireless Systems](#二阅读论文radio-transformer-networks-attention-models-for-learning-to-synchronize-in-wireless-systems)
    - [三、AMBER代码实现](#三amber代码实现-1)
    - [四、下周计划](#四下周计划-7)
  - [`第11周学习总结`](#第11周学习总结)
    - [一、阅读论文Deep Learning for Modulation Classification:Signal Features in Performance Analysis（2020）](#一阅读论文deep-learning-for-modulation-classificationsignal-features-in-performance-analysis2020)
    - [二、训练等级模型](#二训练等级模型)
    - [三、amber](#三amber)
    - [四、下周计划](#四下周计划-8)
  - [`第12周学习总结`](#第12周学习总结)
    - [一、阅读论文](#一阅读论文)
    - [二、总结无线电信号发送与接收过程](#二总结无线电信号发送与接收过程)
    - [三、简单二层CNN仿真](#三简单二层cnn仿真)
    - [四、下周计划](#四下周计划-9)
  - [`第13周学习总结`](#第13周学习总结)
    - [一、搭建Radio Transformer Networks论文中的网络](#一搭建radio-transformer-networks论文中的网络)
    - [二、阅读复神经网络相关论文](#二阅读复神经网络相关论文)
    - [三、整理小论文文字材料](#三整理小论文文字材料)
    - [四、下周计划](#四下周计划-10)
  - [`第14周学习总结`](#第14周学习总结)
    - [一、搭建Radio Transformer Networks论文中的网络](#一搭建radio-transformer-networks论文中的网络-1)
    - [二、学习自定义网络层](#二学习自定义网络层)
    - [三、下周计划](#三下周计划-1)
  - [`第15周学习总结`](#第15周学习总结)
    - [一、阅读论文Modulation pattern Detection Using Complex Convolutions in Deep Learning](#一阅读论文modulation-pattern-detection-using-complex-convolutions-in-deep-learning)
    - [二、阅读论文Dive into Deep Learning Based Automatic Modulation Classification:A Disentangled Approach](#二阅读论文dive-into-deep-learning-based-automatic-modulation-classificationa-disentangled-approach)
    - [三、写小论文材料](#三写小论文材料)
    - [四、下周计划](#四下周计划-11)
  - [`第16周学习总结`](#第16周学习总结)
    - [一、阅读论文Complex-Valued Convolutions for Modulation Recognition using Deep Learning](#一阅读论文complex-valued-convolutions-for-modulation-recognition-using-deep-learning)
    - [二、阅读论文High-Capacity Complex Convolutional Neural Networks for I/Q Modulation Classification](#二阅读论文high-capacity-complex-convolutional-neural-networks-for-iq-modulation-classification)
    - [三、复卷积层](#三复卷积层)
    - [四、STN代码](#四stn代码)

<!-- /TOC -->
###   `第1周学习总结`   
#### 一、整理并总结原来读的注意力机制论文   
[Comparison of Neuronal Attention Models](https://arxiv.org/pdf/1912.03467v1.pdf)   
[One-Dimensional Deep Attention Convolution Network (ODACN) for Signals Classification](https://ieeexplore.ieee.org/document/8926472/references#references)   

#### 二、学习xshell和xftp   
1. 二者如何关联参考[这里](https://www.xshellcn.com/zhishi/guanlian-xftp.html)   
2. 上传原始20G数据集至远端服务器。   

#### 三、学习Linux相关内容   

#### 四、下周计划  
+ 学习注意力机制先关代码，并在jupyter notebook上尝试运行；   
+ 尝试利用xshell运行代码；  
+ 研读注意力机制相关论文；  


###   `第2周学习总结`   
#### 一、学习注意力机制的实现  
> Attention机制大致过程就是分配权重，可直接由一个激活函数为softmax的Dense层实现，Dense层的输出乘以Dense的输入即完成了Attention权重的分配。     

1. 几种实现方式总结：   
> 假设输入注意力模块的形状是(batchsize,feature_cnt,dim)，其中feature_cnt是特征数量，dim为嵌入维度；    

+ 方法一：将输入展开，然后不断地与Dense层相连，Dense的单元数逐步降低，直到降至feature_cnt，最后一层Dense激活函数设为softmax，即可得到注意力权重；    
+ 方法二：将输入先进行一个转置，再对每一维进行softmax，得到每一维的注意力权重，最后合并成单独特征的注意力权重；   
+ 方法三：将输入展开得到feature_cnt×dim维张量，然后对每一维分配注意力权重，再按每个特征dim维进行聚合。   

2. 以上方法中使用到的**融合策略**可以是**平均**的方法，也可以是**拼接**的方法；    
+ 拼接可能产生梯度消失和梯度爆炸，目前大部分论文使用平均来达到加权平均的目的。   

3. 当每个特征嵌入维度不一致时，只有第三种方法能计算出注意力权重。    

#### 二、通过远端服务器运行代码   
+ [try3_attention.py](https://github.com/DeepSec-BJTU/GroupWorks/blob/master/2019_YangYueyi/Attention/try3_attention.py)可以运行； 
+ 因为连接不稳定会出现运行终断的情况；   

#### 三、读《基于深度学习的调制识别技术研究——雷志坤》   

#### 四、下周计划   
+ 实现注意力机制的代码，并自己搭建网络；   
+ 读完雷志坤论文；  
+ 解决xshell连接中断的问题。


###   `第3周学习总结`   
#### 一、搭建VGG+注意力网络架构
代码见[这里](https://github.com/DeepSec-BJTU/GroupWorks/blob/master/2019_YangYueyi/Attention/attention_amc.ipynb)   
#### 二、可视化   
1. 输入信号的可视化   
可以通过将不同的卷积层设置为输出层来实现。

2. 卷积层输出特征的可视化  
卷积核的输出特征从输入图片变换过程的角度展示了 CNN 的特征提取功能。   
代码见[Visialization](https://github.com/DeepSec-BJTU/GroupWorks/blob/master/2019_YangYueyi/Attention/Visualization.ipynb)   
3. 卷积核可视化  
另外一个角度展示卷积核本身的特征，即将卷积层中每一个卷积核的输出视为卷积核提取的特征，如果输入图像的某些局部信息能够使得卷积核的输出尽可能大，那么该卷积核所提取的特征就是使得它的输出尽可能大的输入图像的特定局部信息。    
4. 模型的可视化    
+ Tensorboard   
+ ConvNetDraw   
+ draw_convnet   
+ PlotNeuralNet   
+ NN-SVG   
+ Python + Graphviz   
+ Graphviz - dot   
+ NetworkX   
+  DAFT   

#### 三、阅读雷志坤论文并总结   

#### 四、下周计划   
+ 训练网络   
+ 完善开题报告  


###   `第5周学习总结`   
#### 一、修改开题报告   

#### 二、阅读论文[Context Aware Query Image Representation for Particular Object Retrieval](https://arxiv.org/abs/1703.01226)   
本文有关目标检索领域，给定region of interest(ROI)，从CNN过程中从查询图像中提取代表的建模。使用到编码方法：regional representation of convolutions(R-MAC)。    
传统的图像检索方法只用来自ROI提取的特征代表来编码图像。有两个目的：    
+ 减少背景混乱的干扰，抑制ROI之外分散注意力的部分，他们有时候比ROI更突出        
+ ROI外的区域可以为ROI代表增加上下文信息，增强检索性能    
> 通常在目标检索中，上下⽂信息可以视为ROI外的信息。这种信息在检索过程可以是促进的或是抑制的，也就是会增强或减弱查询图片的区别性。    

所以，抑制还是编码ROI外区域的信息是紧密相连的两个问题，需要适当地**权衡**。      
由于特征图维度很大，需要一些技术编码到固定长度的全局代表，其中**R-MAC**性能表现最好，并且广泛流行采用。     
标准R-MAC缺点在于：在聚合前给预先定义的网格生成的区域分配一致的权重。因为这些区域独独于图像内容产生，背景混乱因此会产生负面的干扰。因此本文的空间注意力计算模型使用到**加权R-MAC（WR-MAC）**来提高性能。     

#### 三、学习空间转移网络（STN）    
1. 空间变换不变性：如果网络能够对经过平移、旋转、缩放及裁剪等操作的图⽚得到与未经变换前相同的检测结果，我们就说这个网络具有空间变换不变性（将平移、旋转、缩放及裁剪不变性统称为空间不变性）。  
具有空间变换不变性的网络能够得到更精确地分类结果。传统CNN网络的池化层具有平移不变性（网络在平移小于池化矩阵的范围时具有平移不变性。所以只有平移小于这个范围，才能保证平移不变性。即所带来卷积网络的位移不变性和旋转不变性只是局部的和固定的。并且池化并不擅于处理其它形式的仿射变换。），但是CNN网络对于大尺度的空间变换并不具备不变性。
Spatial Transformer Networks提出的空间网络变换层，具有平移不变性、旋转不变性及缩放不变性等强大的性能。这个网络可以加在现有的卷积网络中，提高分类的准确性。    
2. 空间变换网络主要有如下三个作用：     
+ 可以将输入转换为下一层期望的形式      
+ 可以在训练的过程中自动选择感兴趣的区域特征         
+ 可以实现对各种形变的数据进行空间变换      
3. 在输入图像之后接一个ST是最常见的操作，也是最容易理解的，即自动图像矫正；理论上讲ST是可以以任意数量插入到网络中的任意位置，ST可以起到裁剪的作用，是一种高级的Attention机制。但多个ST无疑增加了网络的深度，其带来的收益价值值得讨论。        
#### 四、下周计划    
+ 进一步学习R-MAC、STN、RPN，读相关论文；   
+ 解决服务器中断的问题，运行代码。     



###   `第6周学习总结`   
#### 一、读论文[Spatial Transformer Network](https://arxiv.org/pdf/1506.02025.pdf)  
详细了解了STN的相关内容。

#### 二、学习STN代码      
代码见[这里](https://github.com/DeepSec-BJTU/GroupWorks/blob/master/2019_YangYueyi/Attention/STN.ipynb)   
原代码中：输入为60×60，STN部分为locnet到BilinearInterpolation，后面接了两层简单的卷积层和全连接层（只采用极少量数据验证代码，还没有具体根据信号星座图修改网络架构）

#### 三、重新生成星座图，熟悉理想信道下不同调制类型的星座图，并观察与所用数据集生成的星座图的区别。
> 在运行STN代码时，发现原来生成的星座图图片包括标题，坐标等信息，而学习网络在读取输入图像时将这些内容也当作输入进行处理，所以考虑通过剪裁或重新生成星座图的方法，最后选择重新生成只包含星座点的图片。    

初步选择SNR大于0dB的数据，每种调制类型生成200个星座图（受限于电脑内存和速度）    
![alt img](https://shitu-query-bj.bj.bcebos.com/2020-10-18/22/80bd0f2bb33e3347?authorization=bce-auth-v1%2F7e22d8caf5af46cc9310f1e3021709f3%2F2020-10-18T14%3A08%3A20Z%2F300%2Fhost%2Fd722e95a6c172570c1a03692a760dbf536ee7142bc0f21d6a45efa265cc25f3e)     

#### 四、下周计划     
+ 完成开题答辩ppt；    
+ 对开题报告中的内容仔细查阅，补漏；     
+ 读论文。    


###   `第7周学习总结`   
#### 一、准备开题答辩

#### 二、读论文[PARTICULAR OBJECT RETRIEVAL WITH INTEGRAL MAX-POOLING OF CNN ACTIVATIONS](https://arxiv.org/abs/1511.05879)  
本文：  
1.根据卷积层激励提出一个紧致图像表示，不需要重复输入图像到网络中。在初始检索以及重排序中都使用图像的原始表示。就是说，CNN表示的特征向量用在这俩个过程中。    
2.使用了积分图像来近似max-pooling，用于物体定位（generalized mean)     
3.定位的方法用于图像重排序，定义了查询扩张QE方法    

#### 三、下周计划    
+ 测试STN对图像的处理；    
+ 阅读R-MAC及其他相关论文。


###   `第8周学习总结`   
#### 一、学习STN的处理过程    
STN由三个部分组成，分别是：  
（1）Localisation Network：可以是ConVNet或简单的Fc-Net，输出节点数为6，即得到图像变换的参数theta（任何变换可以由6各参数表示）;   
（2）Grid Generator：输出和输入尺寸一致的参数采样网格；    
（3）Sampler：选择合适的插值方法（实验采用双线性插值Bilinearinterpolation），STN输出相应位置插入输入的相应像素。插值方法一定要可微，保证损失梯度可以流回Localisation Network。    
1. 通过设置不同的theta,测试STN对图像进行图像变换的可行性。     
代码见[这里](https://github.com/DeepSec-BJTU/GroupWorks/blob/master/2019_YangYueyi/Attention/stn_module.ipynb)     
> 通过训练整体网络，Localisation Network会输出更精确的theta值对图像进行变换。假如说我们有一个逆时针旋转90度的图像，我们希望比如训练2轮后STN可以把它顺时针旋转45度，5轮后可以完全旋转90度，输出和标准的图像一样，这样更容易分类。   
2. 目前存在的疑问：Localisation Network如何选择合适

#### 二、使用 screen 管理远程会话    
在远程服务器执行的时间太长了。必须等待它执行完毕，在此期间可不能关掉窗口或者断开连接，否则这个任务就会被杀掉。    
> Screen是一个可以在多个进程之间多路复用一个物理终端的窗口管理器。Screen中有会话的概念，用户可以在一个screen会话中创建多个screen窗口，在每一个screen窗口中就像操作一个真实的telnet/SSH连接窗口那样。 

1.在screen中创建一个新的窗口有这样几种方式：   
+ 直接在命令行键入screen命令    
+ Screen命令后跟你要执行的程序    
2. 不中断screen窗口中程序的运行而暂时断开（detach）screen会话（在screen窗口键入C-a d），并在随后时间重新连接（attach）该会话，重新控制各窗口中运行的程序（screen -r socket号）    

#### 三、阅读论文[A practical theory for designing very deep convolutional neural networks](http://www.kaggle.com/blobs/download/forum-message-attachment-files/2287/A%20practical%20theory%20for%20designing%20very%20deep%20convolutional%20neural%20networks.pdf)      
把设计DCNN转为约束最优化问题。       
> 增加深度貌似符合常识用来提高学习能力，但同时线性增加了模型尺寸和计算消耗。随意增加层数不会帮助甚至抑制性能。     

+ 提出：把卷积网络分为两个层：classifier level和feature level。classifier level用一个固定的简单设计，集中于在feature level设计很深的结构   
+ 优化目标：最大化层数    
+ 约束：（1）每层的c值不能太小，c值为测量学习更多复杂部分的能力的尺度。（2）feature level最高层接收域不能大于图像尺寸。     
该方法不依赖于任务，只依赖于原始图像尺寸和固定的滤波器尺寸。当然，如果加入和任务相关的知识会有更好的表现，比如cyclic pooling, rolling network等。   

#### 四、下周计划    
+ 学习并实现特征选择相关代码；     
+ 研读论文。  

###   `第9周学习总结`   
#### 一、阅读论文[Deep Image Retrieval:Learning gloabal representations for image retrieval](https://arxiv.org/abs/1604.01325)    
贡献1：使用三流孪生网络，优化R-MAC向量权重；并提出利用ranking triplet loss调整网络权重；优点在于：（1）直接优化等级目标；（2）可以用和测试阶段一样的高分辨率图像训练网络。         
贡献2：提出利用RPN（region proposal network）代替使用rigid网格的方法，来提取关键的区域。     

#### 二、空间池化金字塔（SPP）    
构建的网络可以输入任意大小的图片，比R-CNN快很多倍；   
R-CNN：直接从原始图片中提取特征，在原始图片上提取n个区域，然后对每一个候选区域进行一次卷积计算；      
SPP-net：则在卷积原始图像之后的特征图上提取候选区域的特征，所有的卷积计算只进行了一次，效率大大提高。    

#### 三、amber代码实现    
在radioML.2016A数据集上测试amber特征选择的作用。代码见[这里](https://github.com/DeepSec-BJTU/GroupWorks/blob/master/2019_YangYueyi/feature%20selection/amber_2016.ipynb)     

#### 四、下周计划    
+ 完成amber在2016版数据的完整特征选择过程；   
+ 尝试在2018版数据上进行amber算法；   
+ 阅读论文。

###   `第10周学习总结`   
#### 一、阅读论文[Deep Architectures for Modulation Recognition](https://arxiv.org/pdf/1703.09197v1.pdf)      
对比了简单CNN不同参数如：卷积层尺寸，滤波器尺寸，网络深度对调制识别性能的影响；还对Resnet，Inception Modules，CLDNN进行了学习。   
结论：无线电调制识别不受网络深度的限制，进一步的工作应集中在改善学习到的同步和均衡上。这些工作中的这些方法和网络体系结构可以学习转换RF数据以消除无线信道的影响。当前正在研究的一个示例是使用空间变换来均衡和同步输入波形。      

#### 二、阅读论文[Radio Transformer Networks: Attention Models for Learning to Synchronize in Wireless Systems](https://arxiv.org/pdf/1605.00716.pdf)     
> 通过利用空间变换器网络并引入新的适合无线电域的变换，将学习到的注意力模型引入无线电机器学习领域，以完成调制识别的任务。 

+ 在原来的工作中，直接从数据集中（信道损耗有振荡器漂移，时钟漂移，衰落，噪声）学习时域特征，在高低SNR下都表现良好。但是，我们在这项工作中没有引起注意的概念，而是迫使不同的网络学习对每种这些信道效应不变的特征。      
+ 提出Radio Transformer Network (RTN)：在STN的结构上，引入无线电域特定的参数转换。直接学习如何在无线系统中同步，通过在分类之前帮助标准化接收信号来超过没有注意力版本的性能。能够对时间和符号速率，相偏和频偏恢复。      
+ 实验结果表明：提出的方法可以有效地学习使用具有特定于领域的变换和层配置的深度卷积神经网络进行同步。使用学习过的估计器对时间，时间扩散，频率和相位偏移进行归一化确实可以有效地改善我们的调制分类性能。        

#### 三、AMBER代码实现      
1. RM模型使用AMC领域效果较好的CLDNN模型，数据集大小为159744，改变batch_size和训练集测试集比例进行多次实验，目前batch_size=512,训：验：测=6:2:2时evaluate结果为[1.310968,0.58127]。     
2. 特征选择过程还在进行中。     

#### 四、下周计划      
+ 继续进行AMBER代码仿真；   
+ 得到性能更佳的RM模型；    
+ 阅读论文。

###   `第11周学习总结`   
#### 一、阅读论文[Deep Learning for Modulation Classification:Signal Features in Performance Analysis（2020）](https://ieeexplore.ieee.org/document/9090764)     
+ 本文研究了：   
  1. 从三种输入数据：特征（矩和累积量）、用PCA技术压缩的时域信号向量、未压缩的幅-相向量；    
  2. 三种模型：简单的两层CNN、四层CNN、双流CNN；    
  3. 重要的结构参数：卷积层的核尺寸。   
+ 数据集：RadioML2016.10a     
+ 结论：   
  1. 增加核维度降低准确率；    
  2. 最适合的信号代表是时域的，相似的调制类型累积量值数量级一样，难以区分；   
  3. 对于信号数据集，模型越简单（层数越少）越有优势。     
   
#### 二、训练等级模型   
> 在服务器上运行代码，数据集为512k（638976）大小，4.57GB。模型为CLDNN。    
+ python 后台运行的方法：nohup python -u xxx.py >> xxx.log 2>&1 &   
+ 研究不同（train:test)比例对相同模型的影响：0.6，0.7，0.8，0.9，0.95，0.96，0.98；实验得0.95的evaluate结果最好：[1.3503315082204268, 0.5399230022279902]     

#### 三、amber    
+ 问题1：在本机运行时，训练autoencoder原代码中用的“binary_crossentropy"，由于输入存在负数，导致loss为负数。所以利用MinMaxScaler对数据归一化；    
+ 问题2：代码运行速度太慢。利用time()找到耗时最多的位置；    
+ 目前正在服务器后台上进行AMBER代码的运行，速度提升很多。   

#### 四、下周计划    
+ 阅读论文；    
+ 研究batch_size对等级模型的影响，提升RM分类准确率；   
+ amber。     

###   `第12周学习总结`   
#### 一、阅读论文       

#### 二、总结无线电信号发送与接收过程        

#### 三、简单二层CNN仿真     

#### 四、下周计划     
+ RTN仿真；       
+ 写论文相关资料。         

###   `第13周学习总结`   
#### 一、搭建Radio Transformer Networks论文中的网络    
RTN模块中包括（1）复卷积层和（2）复数转换为能量和相位的层（该部分代码未完成）；   

#### 二、阅读复神经网络相关论文     

#### 三、整理小论文文字材料      

#### 四、下周计划    
+ RTN代码部分进行实卷积层的搭建和仿真；    
+ 学习复卷积层代码并尝试实现；   
+ 写小论文材料。

###   `第14周学习总结`   
#### 一、搭建Radio Transformer Networks论文中的网络     
![img](https://shitu-query-gz.gz.bcebos.com/2020-12-14/11/40db019919905bde?authorization=bce-auth-v1%2F7e22d8caf5af46cc9310f1e3021709f3%2F2020-12-14T03%3A08%3A38Z%2F300%2Fhost%2Fdd1fd038a1f2ab48056c7f75c22db863639ddd6da654a41e71bfa75de3301350)      
1. 尝试了(1)模块中不加前两层的网络结构，但是评估结果很差，loss是1.8左右（[代码](https://github.com/DeepSec-BJTU/GroupWorks/blob/master/2019_YangYueyi/Attention/rtn_2016_realcon.ipynb)）；   
   ![img](https://shitu-query-gz.gz.bcebos.com/2020-12-14/11/bec116cf7b92e940?authorization=bce-auth-v1%2F7e22d8caf5af46cc9310f1e3021709f3%2F2020-12-14T03%3A13%3A31Z%2F300%2Fhost%2Fc8d554e14d26560c36711e033cc0236efacac4871829ecb74352e5d273f0f35c)
2. 加入了一层ComplexConv1D层，效果也不好（[代码](https://github.com/DeepSec-BJTU/GroupWorks/blob/master/2019_YangYueyi/Attention/rtn_2016_complexconv.ipynb)）;    
   卷积层代码代码见[这里](https://github.com/DeepSec-BJTU/GroupWorks/tree/master/2019_YangYueyi/complexnn)

#### 二、学习自定义网络层      
尝试搭建RTN中的Complex to Power and Phase层        

#### 三、下周计划    
+ 继续RTN代码部分进行实卷积层的搭建和仿真；    
+ 实现自定义层；   
+ 写小论文材料。

###   `第15周学习总结`   
#### 一、阅读论文[Modulation pattern Detection Using Complex Convolutions in Deep Learning](https://www.researchgate.net/publication/344971328_Modulation_Pattern_Detection_Using_Complex_Convolutions_in_Deep_Learning/stats#fullTextFileContent)    
> 本文介绍了利用复卷积对调制识别性能的提升。    
+ 网络：   
  (1)CNN2：2层卷积+2层Dense+softlayer;     
  (2)Complex：在CNN2的基础上在第一层加入复卷积层；   
  (3)CNN2-257：为了和Complex公平对比，在CNN2的基础上增加参数至和Complex相近的程度；    
+ 数据集：RadioML 2016.10A    
+ 3个实验：   
  （1）低训高测；（2）高训低测（低：SNR[-20,-2],高：[0，18]）；（3）在所有SNR下测试       
+ 结果：    
  （1）SNR大于2dB时，(2)网络准确率超过80%；    
  （2）实验1：网络2区分某些相似调制类型的能力更强；实验2：3个网络都很难得到很好的性能；实验3：网络2更优。   
+ 对神经网络学习到的可视化。   

#### 二、阅读论文[Dive into Deep Learning Based Automatic Modulation Classification:A Disentangled Approach](https://ieeexplore.ieee.org/document/9121246)       
> 本文抛弃端到端的训练策略，提出一种改进的方法。     
文中提到STN相关研究利用端到端的方法容易在功能上和后接的网络耦合，即陷入过拟合，使得性能不能达到理想状态。提出的改进的训练方法是：分开训练。   
+ 模型：      
A. BASELINE MODELS
   1. CM-CNN model for RML2016.10A,
   （two modules：Correction module (CM)：一个简单的MLP，用于预测频偏和相偏；Classification module ）      
   2. Resnet , VGG model for RML2018.10A       

B. PROPOSED MODEL（3个模块）     
   1. SNR预测模块：把SNR类型分为3类 ；   
   2. 分类模块：只用高SNR信号训练，所以不需要太多参数，设计了2个简化版的Resnet：Resnetv1，Resnetv2；      
   3. 信号处理模块：当SNR没有低到某种程度时，可以把信号重构到⼀个更合适的形式（和图像恢复领域的任务类似）。     

+ 实验结果：
  1. SNR预测模块：2016的结果没2018的好，因为符号长度短，但是不影响，因为只有高SNR的信号不会被送到信号处理模块；        
  2. 分类模块：         
     + 2016：对比Resnetv1 and CNN module from CM-CNN model，       
    （Training strategy两种case:(1)训练所有SNR（2）训练⾼SNR。在所有SNR情况下测试）      
     + 2018：对比VGG, Resnet, and proposed Resnetv2（Training strategy同上）。              
     + （2）比（1）好；               
     + （2）下，Resnetv1在高SNR优于CNN，但是在低SNR下差。（因为测试信号是低SNR时，高SNR训练的模型之间的比较就没有意义了/Resnetv1低噪声更敏感。）   
     + 准确率的提高源于高阶调制的准确识别（高阶调制对噪声更敏感）   
     + 本文提出的模型不需要dropout层也不会出现过拟合。     
  3. 信号处理模块：          
     Median SNR的信号用于训练；   
     + 性能提升源于低阶调制，while⾼阶下降（对噪声敏感，难以重构）       

#### 三、写小论文材料        

#### 四、下周计划     
+ 读论文；   
+ 学习AMC相关复卷积代码；       
+ 写论文。    

###   `第16周学习总结`   
#### 一、阅读论文[Complex-Valued Convolutions for Modulation Recognition using Deep Learning](https://www.researchgate.net/publication/343123601_Complex-Valued_Convolutions_for_Modulation_Recognition_using_Deep_Learning)        
具体介绍复卷积处理复输入的实现，对比CNN2,Complex和CNN2-260三种网络的性能；    
数据集：RadioML2016.10a      
结论：加入复卷积，可能效率不高，但是性能有提升。     

#### 二、阅读论文[High-Capacity Complex Convolutional Neural Networks for I/Q Modulation Classification](https://www.researchgate.net/publication/344802862_High-Capacity_Complex_Convolutional_Neural_Networks_For_IQ_Modulation_Classification)        
研究了复杂模型加入复卷积层对AMC性能的影响，主要研究了ResNet,DenseNet和Dense ResNet及其分别加入复卷积层的网络；       
数据集：RadioML2016.10a   
结论：在相同参数规模下的不同模型，加入复卷积层的在低SNR下性能更佳；Dense ResNet-68 C性能最好。       

#### 三、复卷积层      
对比CNN，CNN2,complex_CNN,complex_CNN2模型；    
数据集：RadioML2016.04c；       
代码见[这里](https://github.com/DeepSec-BJTU/GroupWorks/blob/master/2019_YangYueyi/complexcnn_amc/cnn_complex_2016c.ipynb)              
利用数据集RadioML2016.10a训练的代码见[这里](https://github.com/DeepSec-BJTU/GroupWorks/blob/master/2019_YangYueyi/complexcnn_amc/cnn_complex_2016a.ipynb)                

#### 四、STN代码    
代码见[这里](https://github.com/DeepSec-BJTU/GroupWorks/blob/master/2019_YangYueyi/Attention/RTN_2016_Complex.ipynb)           